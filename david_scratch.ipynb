{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import NamedTuple\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env_values() -> dict[str, str|None]:\n",
    "    return dotenv_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_values: dict[str, str|None] = get_env_values()\n",
    "\n",
    "# NamedTuple type hint\n",
    "class ParametersType(NamedTuple):\n",
    "    data_dir: PosixPath # Platform neutral pathlib PosixPath to data directory\n",
    "    acs_path: PosixPath # Platform neutral pathlib PosixPath to ACS data\n",
    "    db_path: PosixPath # Platform neutral pathlib PosixPath to SQLite3 database\n",
    "    db_connection: sqlite3.Connection # SQLite3 database connection\n",
    "    openai_api_key: str # OpenAI API key\n",
    "    huggingfacehub_api_token: str # HuggingFace API token\n",
    "\n",
    "Parameters: ParametersType = ParametersType(\n",
    "    data_dir = Path.cwd() / \"Data\",\n",
    "    acs_path = Path.cwd() / \"Data/ACS_2012_21.csv\",\n",
    "    db_path= Path.cwd() / \"Data/data.sqlite3\",\n",
    "    db_connection = sqlite3.connect(Path.cwd() / \"Data/data.sqlite3\"),  # \":memory:\", \"Data/data.sqlite3\", \"Data/acs.sqlite3\"\n",
    "    openai_api_key = env_values[\"OPENAI_API_KEY\"],\n",
    "    huggingfacehub_api_token = env_values[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseInfoExtractor:\n",
    "    \"\"\"\n",
    "    A class for extracting information about tables and columns from a SQLite database.\n",
    "\n",
    "    Attributes:\n",
    "    - db_path (str): The path to the SQLite database file.\n",
    "    - conn (sqlite3.Connection): The connection object to the database.\n",
    "    - cursor (sqlite3.Cursor): The cursor object for executing SQL queries.\n",
    "\n",
    "    Methods:\n",
    "    - extract_info() -> dict[str, dict[str, list[str]]]: Returns a dictionary containing information about each table in the database.\n",
    "    \"\"\"\n",
    "    def __init__(self, db_path: PosixPath) -> None:\n",
    "        self.db_path = db_path\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "\n",
    "    def extract_info(self) -> dict[str, dict[str, list[str]]]:\n",
    "        tables: dict[str, str] = {}\n",
    "        self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        table_names: list[str] = [row[0] for row in self.cursor.fetchall()]\n",
    "        for table_name in table_names:\n",
    "            columns: list[str] = []\n",
    "            column_types: list[str] = []\n",
    "            self.cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "            for row in self.cursor.fetchall():\n",
    "                columns.append(row[1])\n",
    "                column_types.append(row[2])\n",
    "            tables[table_name] = {\"columns\": columns, \"column_types\": column_types}\n",
    "        return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate DatabaseInfoExtractor\n",
    "db_info_extractor = DatabaseInfoExtractor(Parameters.db_path)\n",
    "\n",
    "# Extract information about the database\n",
    "db_info = db_info_extractor.extract_info()\n",
    "print(db_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/gozer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/gozer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/gozer/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Install punkt and stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_synonym(word: str) -> str:\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "    if len(synonyms) > 0:\n",
    "        return synonyms[0]\n",
    "    else:\n",
    "        return \"No synonym found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['many', 'five', 'nine', 'year', 'olds', 'alabama', '2021']\n"
     ]
    }
   ],
   "source": [
    "# Sample sentence\n",
    "# sentence = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "# sentence = \"How many geographic areas are in the acs table?\"\n",
    "sentence = \"How many five to nine year olds are in Alabama in 2021?\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "# Remove stop words and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token.lower() for token in tokens if token.lower() not in stop_words and token not in string.punctuation]\n",
    "print(filtered_tokens)\n",
    "\n",
    "# Join the filtered tokens back into a sentence\n",
    "# filtered_sentence = ' '.join(filtered_tokens)\n",
    "# print(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w='many' - find_synonym(w)='many'\n",
      "w='five' - find_synonym(w)='five'\n",
      "w='nine' - find_synonym(w)='nine'\n",
      "w='year' - find_synonym(w)='year'\n",
      "w='olds' - find_synonym(w)='old'\n",
      "w='alabama' - find_synonym(w)='Alabama'\n",
      "w='2021' - find_synonym(w)='No synonym found'\n"
     ]
    }
   ],
   "source": [
    "for w in filtered_tokens:\n",
    "    print(f\"{w=} - {find_synonym(w)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
