{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".env contains\n",
    "OPENAI_API_KEY=<your key without quotes>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import sketch\n",
    "import openai\n",
    "import plotly.express as px # Needed to import this as px so an error was not thrown in the generated code\n",
    "import kaleido\n",
    "import pandas as pd\n",
    "from pandas_llm import PandasLLM\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "from collections import namedtuple\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NamedTuple type hint\n",
    "class ParametersType(NamedTuple):\n",
    "    data_dir: PosixPath # Platform neutral pathlib PosixPath to data directory\n",
    "    acs_path: PosixPath # Platform neutral pathlib PosixPath to ACS data\n",
    "    db_path: PosixPath # Platform neutral pathlib PosixPath to SQLite3 database\n",
    "    db_connection: sqlite3.Connection # SQLite3 database connection\n",
    "    openai_api_key: str # OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters: ParametersType = ParametersType(\n",
    "    data_dir = Path.cwd() / \"Data\",\n",
    "    acs_path = Path.cwd() / \"Data/ACS_2012_21.csv\",\n",
    "    db_path= Path.cwd() / \"Data/data.sqlite3\",\n",
    "    db_connection = sqlite3.connect(Path.cwd() / \"Data/data.sqlite3\"),  # \":memory:\"\n",
    "    openai_api_key = os.environ[\"OPENAI_API_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all tables in SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('saacempratio',),\n",
       " ('saacartsva',),\n",
       " ('saacemplq',),\n",
       " ('saacvaratio',),\n",
       " ('saaccompratio',),\n",
       " ('saacartsemp',),\n",
       " ('saacvalq',),\n",
       " ('saacartscomp',),\n",
       " ('saaccomplq',),\n",
       " ('sasummary',),\n",
       " ('saocomp',),\n",
       " ('saova',),\n",
       " ('saoactva',),\n",
       " ('saoemp',),\n",
       " ('sapce4',),\n",
       " ('sapce3',),\n",
       " ('sapce1',),\n",
       " ('sapce2',),\n",
       " ('sainc7h',),\n",
       " ('saemp25s',),\n",
       " ('sainc35',),\n",
       " ('sainc51',),\n",
       " ('sainc50',),\n",
       " ('saemp25n',),\n",
       " ('sainc7n',),\n",
       " ('sainc7s',),\n",
       " ('sainc1',),\n",
       " ('saemp27n',),\n",
       " ('sainc6n',),\n",
       " ('sainc5n',),\n",
       " ('sainc5h',),\n",
       " ('sainc40',),\n",
       " ('saemp27s',),\n",
       " ('sainc5s',),\n",
       " ('sainc70',),\n",
       " ('sainc91',),\n",
       " ('sainc6s',),\n",
       " ('sainc4',),\n",
       " ('sainc30',),\n",
       " ('sainc45',),\n",
       " ('sagdp4n',),\n",
       " ('sagdp11n',),\n",
       " ('sagdp2n',),\n",
       " ('sagdp6n',),\n",
       " ('sagdp9n',),\n",
       " ('sagdp1',),\n",
       " ('sagdp3n',),\n",
       " ('sagdp8n',),\n",
       " ('sagdp7n',),\n",
       " ('sagdp5n',),\n",
       " ('acs',),\n",
       " ('saacempratio_definitions',),\n",
       " ('saacartscomp_definitions',),\n",
       " ('saacemplq_definitions',),\n",
       " ('saacvalq_definitions',),\n",
       " ('saacvaratio_definitions',),\n",
       " ('saaccompratio_definitions',),\n",
       " ('saacartsva_definitions',),\n",
       " ('saacartsemp_definitions',),\n",
       " ('saaccomplq_definitions',),\n",
       " ('sarpp_definitions',),\n",
       " ('sasummary_definitions',),\n",
       " ('sairpd_definitions',),\n",
       " ('sarpi_definitions',),\n",
       " ('sapce2_definitions',),\n",
       " ('sapce4_definitions',),\n",
       " ('sapce1_definitions',),\n",
       " ('sapce3_definitions',),\n",
       " ('sainc5s_definitions',),\n",
       " ('sainc50_definitions',),\n",
       " ('saemp27n_definitions',),\n",
       " ('sainc40_definitions',),\n",
       " ('sainc1_definitions',),\n",
       " ('saemp25n_definitions',),\n",
       " ('sainc5n_definitions',),\n",
       " ('sainc4_definitions',),\n",
       " ('sainc91_definitions',),\n",
       " ('sainc7n_definitions',),\n",
       " ('sainc51_definitions',),\n",
       " ('sainc7s_definitions',),\n",
       " ('sainc5h_definitions',),\n",
       " ('sainc70_definitions',),\n",
       " ('sainc6s_definitions',),\n",
       " ('sainc35_definitions',),\n",
       " ('sainc6n_definitions',),\n",
       " ('sainc45_definitions',),\n",
       " ('sainc30_definitions',),\n",
       " ('saemp27s_definitions',),\n",
       " ('sainc7h_definitions',),\n",
       " ('saemp25s_definitions',),\n",
       " ('sagdp9n_definitions',),\n",
       " ('sagdp11n_definitions',),\n",
       " ('sagdp6n_definitions',),\n",
       " ('sagdp5n_definitions',),\n",
       " ('sagdp1_definitions',),\n",
       " ('sagdp3n_definitions',),\n",
       " ('sagdp4n_definitions',),\n",
       " ('sagdp8n_definitions',),\n",
       " ('sagdp7n_definitions',),\n",
       " ('sagdp2n_definitions',),\n",
       " ('saacartscomp_footnotes',),\n",
       " ('saaccompratio_footnotes',),\n",
       " ('saacemplq_footnotes',),\n",
       " ('saacartsemp_footnotes',),\n",
       " ('saacvalq_footnotes',),\n",
       " ('saacvaratio_footnotes',),\n",
       " ('saaccomplq_footnotes',),\n",
       " ('saacempratio_footnotes',),\n",
       " ('saacartsva_footnotes',),\n",
       " ('sarpi_footnotes',),\n",
       " ('sasummary_footnotes',),\n",
       " ('sarpp_footnotes',),\n",
       " ('sairpd_footnotes',),\n",
       " ('saoemp_footnotes',),\n",
       " ('saova_footnotes',),\n",
       " ('saocomp_footnotes',),\n",
       " ('saoactva_footnotes',),\n",
       " ('sapce1_footnotes',),\n",
       " ('sapce3_footnotes',),\n",
       " ('sapce2_footnotes',),\n",
       " ('sapce4_footnotes',),\n",
       " ('sainc7s_footnotes',),\n",
       " ('sainc50_footnotes',),\n",
       " ('sainc35_footnotes',),\n",
       " ('sainc6n_footnotes',),\n",
       " ('sainc7h_footnotes',),\n",
       " ('sainc5s_footnotes',),\n",
       " ('sainc5n_footnotes',),\n",
       " ('saemp25s_footnotes',),\n",
       " ('sainc45_footnotes',),\n",
       " ('sainc91_footnotes',),\n",
       " ('sainc70_footnotes',),\n",
       " ('sainc7n_footnotes',),\n",
       " ('sainc5h_footnotes',),\n",
       " ('sainc40_footnotes',),\n",
       " ('saemp27s_footnotes',),\n",
       " ('sainc51_footnotes',),\n",
       " ('sainc30_footnotes',),\n",
       " ('sainc4_footnotes',),\n",
       " ('sainc1_footnotes',),\n",
       " ('saemp25n_footnotes',),\n",
       " ('saemp27n_footnotes',),\n",
       " ('sainc6s_footnotes',),\n",
       " ('sagdp1_footnotes',),\n",
       " ('sagdp2n_footnotes',),\n",
       " ('sagdp4n_footnotes',),\n",
       " ('sagdp11n_footnotes',),\n",
       " ('sagdp9n_footnotes',),\n",
       " ('sagdp7n_footnotes',),\n",
       " ('sagdp5n_footnotes',),\n",
       " ('sagdp8n_footnotes',),\n",
       " ('sagdp6n_footnotes',),\n",
       " ('sagdp3n_footnotes',)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = Parameters.db_connection.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables: list[tuple] = cursor.fetchall()\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_df: pd.DataFrame = pd.read_csv(Parameters.acs_path)\n",
    "acs_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "display(acs_df.info())\n",
    "display(acs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Please provide python code to ask openai a question and retrieve the answer\n",
    "\n",
    "To ask OpenAI a question and retrieve the answer, you can use the OpenAI API.\n",
    "Here's an example Python code that demonstrates how to do this using the openai package:\n",
    "\n",
    "In this example, you need to replace \"YOUR_API_KEY\" with your actual API key,\n",
    "which you can obtain by signing up for OpenAI's API at https://beta.openai.com/signup/.\n",
    "\n",
    "The ask_openai function takes three parameters: the question you want to ask,\n",
    "the name of the OpenAI model you want to use (e.g., \"davinci\" or \"curie\"),\n",
    "and the max_length of the generated answer (in number of tokens).\n",
    "\n",
    "The function sends a request to the OpenAI API using the openai.Completion.create method,\n",
    "which takes the engine, prompt, and max_tokens as parameters. The response is a list of\n",
    "completions (i.e., possible answers), and we take the first one (which is usually the most likely answer)\n",
    "and return it as a string.\n",
    "\"\"\"\n",
    "\n",
    "openai.api_key = Parameters.openai_api_key # \"YOUR_API_KEY\" # replace with your API key\n",
    "\n",
    "def ask_openai(question, model, max_length):\n",
    "    prompt = f\"Q: {question}\\nA:\"\n",
    "    completions = openai.Completion.create(\n",
    "        engine=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_length\n",
    "    )\n",
    "    answer = completions.choices[0].text.strip()\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "question = \"What is the capital of France?\"\n",
    "model = \"davinci\"\n",
    "max_length = 100\n",
    "answer = ask_openai(question, model, max_length)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LangChain](https://pypi.org/project/langchain/)\n",
    "https://coinsbench.com/chat-with-your-databases-using-langchain-bb7d31ed2e76  \n",
    "https://medium.com/@hannanmentor/python-custom-chatgpt-with-your-own-data-f307635dd5bd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that LangChain works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple LLM call Using LangChain\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=Parameters.openai_api_key)\n",
    "question = \"Which language is used to create chatgpt ?\"\n",
    "print(question, llm(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prompt template and running the LLM chain\n",
    "template = \"What are the top {n} resources to learn {language} programming?\"\n",
    "prompt = PromptTemplate(template=template,input_variables=['n','language'])\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "input = {'n':3,'language':'Python'}\n",
    "print(chain.run(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, SQLDatabase  #, SQLDatabaseChain, PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLDatabase.create_table_from_df(df=acs_df, table_name=\"acs\", db_connection=Parameters.db_connection)  # Create table from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LangChain to answers quetions using a SQLite3 database\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=Parameters.openai_api_key)\n",
    "db = SQLDatabase(db_connection=Parameters.db_connection)\n",
    "question = \"What is the population of Kentucky?\"\n",
    "print(question, llm(question,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///Data/data.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema(_):\n",
    "    return db.get_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable.passthrough import RunnablePassthrough  # Try without .passthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'RunnablePassthrough' has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/gozer/python/GenAI_Insights/langchain_david.ipynb Cell 29\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gozer/python/GenAI_Insights/langchain_david.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m ChatOpenAI()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gozer/python/GenAI_Insights/langchain_david.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sql_response \u001b[39m=\u001b[39m (\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gozer/python/GenAI_Insights/langchain_david.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     RunnablePassthrough\u001b[39m.\u001b[39;49massign(schema\u001b[39m=\u001b[39mget_schema)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gozer/python/GenAI_Insights/langchain_david.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m|\u001b[39m prompt\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gozer/python/GenAI_Insights/langchain_david.ipynb#X64sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m|\u001b[39m model\u001b[39m.\u001b[39mbind(stop\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mSQLResult:\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gozer/python/GenAI_Insights/langchain_david.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m|\u001b[39m StrOutputParser()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gozer/python/GenAI_Insights/langchain_david.ipynb#X64sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'RunnablePassthrough' has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI()\n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | model.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# setup llm\n",
    "llm = OpenAI(temperature=0, openai_api_key=Parameters.openai_api_key)\n",
    "\n",
    "# Create db chain\n",
    "QUERY = \"\"\"\n",
    "Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Setup the database chain\n",
    "db_chain = SQLDatabaseChain(llm=llm, database=Parameters.db_connection, verbose=True)\n",
    "\n",
    "\n",
    "def get_prompt():\n",
    "    print(\"Type 'exit' to quit\")\n",
    "\n",
    "    while True:\n",
    "        prompt = input(\"Enter a prompt: \")\n",
    "\n",
    "        if prompt.lower() == 'exit':\n",
    "            print('Exiting...')\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                question = QUERY.format(question=prompt)\n",
    "                print(db_chain.run(question))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "get_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
